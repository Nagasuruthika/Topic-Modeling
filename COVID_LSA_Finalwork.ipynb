{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COVID-LSA-Finalwork.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPUkhz7K3GkRXIzyEuH04hl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Namyalg/Topic-Modeling/blob/master/COVID_LSA_Finalwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkbttWnDLXyh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "9c788a0f-de2d-4d19-f068-11e8fa198ae6"
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"punkt\")\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "stop = set(stopwords.words('english'))\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from gensim import corpora, models\n",
        "import gensim\n",
        "import string\n",
        "exclude = set(string.punctuation)\n",
        "lemma = WordNetLemmatizer()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8Yh602hLg-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "1d15bb0d-ad45-4d92-f701-898b49fcb726"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "pd.set_option(\"display.max_colwidth\", 200)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8Z56rBnMLj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "from csv import reader\n",
        "tit = []\n",
        "with open(\"/content/COVID-19_title.csv\", 'r') as read_obj:\n",
        "    # pass the file object to reader() to get the reader object\n",
        "    csv_reader = reader(read_obj)\n",
        "    # Iterate over each row in the csv using reader object\n",
        "    for row in csv_reader:\n",
        "        # row variable is a list that represents a row in csv\n",
        "        tit.append(row)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkpkKBtdTzsu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ddb1cea2-777b-420e-dcef-0c6d113b049b"
      },
      "source": [
        "print(tit[:5])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['clinical features culture-proven mycoplasma pneumoniae infections king abdulaziz university hospital jeddah saudi arabia'], ['nitric oxide pro-inflammatory mediator lung diseas'], ['surfactant protein-d pulmonary host defens'], ['role endothelin-1 lung diseas'], ['gene expression epithelial cells response pneumovirus infect']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv7S0-kYT2Lv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "title = tit"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFb2_tXfZxW2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e268c134-0091-4a37-b9ea-a2ed33d3310f"
      },
      "source": [
        "print(title[:3])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['clinical features culture-proven mycoplasma pneumoniae infections king abdulaziz university hospital jeddah saudi arabia'], ['nitric oxide pro-inflammatory mediator lung diseas'], ['surfactant protein-d pulmonary host defens']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-hAn748Z4kO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "title = pd.DataFrame(tit)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8HhYo_7baOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = pd.read_csv(\"/content/COVID-19_title.csv\", header=None)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yneg3VCIc-tV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = d[0]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6zSBPgxZ7-h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "baebf558-a763-48d3-8d34-3ebd230bc07c"
      },
      "source": [
        "print(d.head())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    clinical features culture-proven mycoplasma pneumoniae infections king abdulaziz university hospital jeddah saudi arabia\n",
            "1                                                                          nitric oxide pro-inflammatory mediator lung diseas\n",
            "2                                                                                  surfactant protein-d pulmonary host defens\n",
            "3                                                                                               role endothelin-1 lung diseas\n",
            "4                                                                gene expression epithelial cells response pneumovirus infect\n",
            "Name: 0, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLYA1oetd4-F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "25b3575b-d416-4d35-ca5b-b3aa97452f85"
      },
      "source": [
        "d.dropna()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         clinical features culture-proven mycoplasma pneumoniae infections king abdulaziz university hospital jeddah saudi arabia\n",
              "1                                                                               nitric oxide pro-inflammatory mediator lung diseas\n",
              "2                                                                                       surfactant protein-d pulmonary host defens\n",
              "3                                                                                                    role endothelin-1 lung diseas\n",
              "4                                                                     gene expression epithelial cells response pneumovirus infect\n",
              "                                                                    ...                                                           \n",
              "242103                                                                                        preparation organization major incid\n",
              "242104                                                                                            atrial arrhythmias covid-19 pati\n",
              "242105                                                                                 this next problem cleaning covid-19 respons\n",
              "242106                                                                      screening donor recipient prior solid organ transplant\n",
              "242107                         exploring genomic proteomic variations sars-cov-2 spike glycoprotein computational biology approach\n",
              "Name: 0, Length: 242077, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm-5jO1OaI6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english', \n",
        "max_features= 1000, # keep top 1000 terms \n",
        "max_df = 0.5, \n",
        "smooth_idf=True)\n",
        "v = TfidfVectorizer(decode_error='replace', encoding='utf-8')\n",
        "x = v.fit_transform(d.values.astype('U')) \n",
        "#X = vectorizer.fit_transform(d)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmorzl4feVwc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "520be99f-3360-40b0-be45-f8437ed85eaa"
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# SVD represent documents and terms in vectors \n",
        "svd_model = TruncatedSVD(n_components=70, algorithm='randomized', n_iter=10, random_state=122)\n",
        "\n",
        "svd_model.fit(x)\n",
        "\n",
        "len(svd_model.components_)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mycOR1-QfRLu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "45d5c119-5732-4af1-f51a-9e827d45222b"
      },
      "source": [
        "terms = vectorizer.get_feature_names()\n",
        "\n",
        "for i, comp in enumerate(svd_model.components_):\n",
        "    terms_comp = zip(terms, comp)\n",
        "    sorted_terms = sorted(terms_comp, key= lambda x:x[1], reverse=True)[:7]\n",
        "    print(\"Topic \"+str(i)+\": \")\n",
        "    for t in sorted_terms:\n",
        "        print(t[0])\n",
        "        print(\" \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-622544bce1ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mterms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvd_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mterms_comp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msorted_terms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterms_comp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mget_feature_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \"\"\"\n\u001b[1;32m   1314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m         return [t for t, i in sorted(self.vocabulary_.items(),\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_check_vocabulary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Vocabulary not fitted or provided\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: Vocabulary not fitted or provided"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mI53pPhZoe8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b5c01f5c-5a50-4c14-9dc7-bce8293af53b"
      },
      "source": [
        "print(tit[:4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['clinical features culture-proven mycoplasma pneumoniae infections king abdulaziz university hospital jeddah saudi arabia'], ['nitric oxide pro-inflammatory mediator lung diseas'], ['surfactant protein-d pulmonary host defens'], ['role endothelin-1 lung diseas']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de7l8B_ZQDnD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "21e6330a-3f32-433b-a0e9-bf8afc04939b"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
        "documents = dataset.data\n",
        "len(documents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11314"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JHCVDL8QtlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "news_df = pd.DataFrame({'document':documents})\n",
        "\n",
        "# removing everything except alphabets`\n",
        "news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
        "\n",
        "# removing short words\n",
        "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
        "\n",
        "# make all text lowercase\n",
        "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K0sifJsQ2yR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "# tokenization\n",
        "tokenized_doc = news_df['clean_doc'].apply(lambda x: x.split())\n",
        "\n",
        "# remove stop-words\n",
        "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
        "\n",
        "# de-tokenization\n",
        "detokenized_doc = []\n",
        "for i in range(len(news_df)):\n",
        "    t = ' '.join(tokenized_doc[i])\n",
        "    detokenized_doc.append(t)\n",
        "\n",
        "news_df['clean_doc'] = detokenized_doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlILaxzMQ6Gt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "6fc7cb39-e8cc-4556-b991-fe406142ca1d"
      },
      "source": [
        "print(news_df[\"clean_doc\"].head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    well sure story seem biased disagree statement media ruin israels reputation rediculous media israeli media world lived europe realize incidences described letter occured media whole seem ignore s...\n",
            "1    yeah expect people read actually accept hard atheism need little leap faith jimmy logic runs steam sorry pity sorry feelings denial faith need well pretend happily ever anyway maybe start newsgrou...\n",
            "2    although realize principle strongest points would still like know question sort arab countries want continue think tank charade fixation israel must stop might start asking sort questions arab cou...\n",
            "3    notwithstanding legitimate fuss proposal much change last product area priced suspect clipper phones came customer automatically preregistered government authorities thus aside attempting legitimi...\n",
            "4                     well change scoring playoff pool unfortunately time right certainly post scoring rules tomorrow matter enter anyway good keith keller rangers quakers kkeller mail upenn league champs\n",
            "Name: clean_doc, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Fb1aMs3RHn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}